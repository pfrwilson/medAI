{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fs01/home/abbasgln/codes/medAI/projects/tta\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Loading environment variables\n",
    "load_dotenv()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import typing as tp\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataclasses import dataclass, field\n",
    "import logging\n",
    "import wandb\n",
    "\n",
    "import medAI\n",
    "from medAI.utils.setup import BasicExperiment, BasicExperimentConfig\n",
    "\n",
    "from utils.metrics import MetricCalculator\n",
    "\n",
    "from timm.optim.optim_factory import create_optimizer\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "from datasets.datasets import ExactNCT2013RFImagePatches\n",
    "from medAI.datasets.nct2013 import (\n",
    "    KFoldCohortSelectionOptions,\n",
    "    LeaveOneCenterOutCohortSelectionOptions, \n",
    "    PatchOptions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAVE_OUT='PCC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing positions: 100%|██████████| 658/658 [00:05<00:00, 130.60it/s]\n",
      "Computing positions: 100%|██████████| 1026/1026 [00:09<00:00, 110.25it/s]\n",
      "Computing positions: 100%|██████████| 1599/1599 [00:16<00:00, 94.07it/s] \n"
     ]
    }
   ],
   "source": [
    "###### No support dataset ######\n",
    "\n",
    "from vicreg_pretrain_experiment import PretrainConfig\n",
    "config = PretrainConfig(cohort_selection_config=LeaveOneCenterOutCohortSelectionOptions(leave_out=f\"{LEAVE_OUT}\"))\n",
    "\n",
    "from baseline_experiment import BaselineConfig\n",
    "from torchvision.transforms import v2 as T\n",
    "from torchvision.tv_tensors import Image as TVImage\n",
    "\n",
    "class Transform:\n",
    "    def __init__(selfT, augment=False):\n",
    "        selfT.augment = augment\n",
    "        selfT.size = (256, 256)\n",
    "        # Augmentation\n",
    "        selfT.transform = T.Compose([\n",
    "            T.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n",
    "            T.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0.5),\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomVerticalFlip(p=0.5),\n",
    "        ])  \n",
    "    \n",
    "    def __call__(selfT, item):\n",
    "        patch = item.pop(\"patch\")\n",
    "        patch = copy(patch)\n",
    "        patch = (patch - patch.min()) / (patch.max() - patch.min()) \\\n",
    "            if config.instance_norm else patch\n",
    "        patch = TVImage(patch)\n",
    "        patch = T.Resize(selfT.size, antialias=True)(patch).float()\n",
    "        \n",
    "        label = torch.tensor(item[\"grade\"] != \"Benign\").long()\n",
    "        \n",
    "        if selfT.augment:\n",
    "            patch_augs = torch.stack([selfT.transform(patch) for _ in range(2)], dim=0)\n",
    "            return patch_augs, patch, label, item\n",
    "        \n",
    "        return -1, patch, label, item\n",
    "\n",
    "\n",
    "cohort_selection_options_train = copy(config.cohort_selection_config)\n",
    "cohort_selection_options_train.min_involvement = config.min_involvement_train\n",
    "cohort_selection_options_train.benign_to_cancer_ratio = config.benign_to_cancer_ratio_train\n",
    "cohort_selection_options_train.remove_benign_from_positive_patients = config.remove_benign_from_positive_patients_train\n",
    "\n",
    "train_ds = ExactNCT2013RFImagePatches(\n",
    "    split=\"train\",\n",
    "    transform=Transform(augment=False),\n",
    "    cohort_selection_options=cohort_selection_options_train,\n",
    "    patch_options=config.patch_config,\n",
    "    debug=config.debug,\n",
    ")\n",
    "\n",
    "val_ds = ExactNCT2013RFImagePatches(\n",
    "    split=\"val\",\n",
    "    transform=Transform(augment=False),\n",
    "    cohort_selection_options=config.cohort_selection_config,\n",
    "    patch_options=config.patch_config,\n",
    "    debug=config.debug,\n",
    ")\n",
    "\n",
    "test_ds = ExactNCT2013RFImagePatches(\n",
    "    split=\"test\",\n",
    "    transform=Transform(augment=False),\n",
    "    cohort_selection_options=config.cohort_selection_config,\n",
    "    patch_options=config.patch_config,\n",
    "    debug=config.debug,\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=config.batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=config.batch_size, shuffle=False, num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=config.batch_size, shuffle=False, num_workers=4\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vicreg_pretrain_experiment import TimmFeatureExtractorWrapper\n",
    "from timm.layers.adaptive_avgmax_pool import SelectAdaptivePool2d\n",
    "\n",
    "\n",
    "fe_config = config.model_config\n",
    "\n",
    "# Create the model\n",
    "model: nn.Module = timm.create_model(\n",
    "    fe_config.model_name,\n",
    "    num_classes=fe_config.num_classes,\n",
    "    in_chans=1,\n",
    "    features_only=fe_config.features_only,\n",
    "    norm_layer=lambda channels: nn.GroupNorm(\n",
    "                    num_groups=fe_config.num_groups,\n",
    "                    num_channels=channels\n",
    "                    ))\n",
    "\n",
    "# Separate creation of classifier and global pool from feature extractor\n",
    "global_pool = SelectAdaptivePool2d(\n",
    "    pool_type='avg',\n",
    "    flatten=True,\n",
    "    input_fmt='NCHW',\n",
    "    )\n",
    "\n",
    "model = nn.Sequential(TimmFeatureExtractorWrapper(model), global_pool)\n",
    "\n",
    "\n",
    "# CHECkPOINT_PATH = os.path.join(os.getcwd(), f'logs/tta/vicreg_pretrain_gn_loco/vicreg_pretrain_gn_loco_{LEAVE_OUT}/', 'best_model.ckpt')\n",
    "# CHECkPOINT_PATH = os.path.join(os.getcwd(), f'logs/tta/vicreg_pretrn_5e-3-20linprob_gn_loco/vicreg_pretrn_5e-3-20linprob_gn_loco_{LEAVE_OUT}/', 'best_model.ckpt')\n",
    "# CHECkPOINT_PATH = os.path.join(os.getcwd(), f'logs/tta/vicreg_pretrn_5e-3-15linprob_100ep_actual2048zdim_gn_loco_{LEAVE_OUT}/', 'best_model.ckpt')\n",
    "CHECkPOINT_PATH = os.path.join(os.getcwd(), f'logs/tta/vicreg_pretrn_2048zdim_gn_loco/vicreg_pretrn_2048zdim_gn_loco_{LEAVE_OUT}/', 'best_model.ckpt')\n",
    "\n",
    "model.load_state_dict(torch.load(CHECkPOINT_PATH)['model'])\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "a = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get train reprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404d820ac3074b59973c444a101334ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/803 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.linear_prob import LinearProb\n",
    "\n",
    "loader = train_loader\n",
    "\n",
    "desc = \"train\"\n",
    "metric_calculator = MetricCalculator()\n",
    "# linear_prob = nn.Linear(512, 2).cuda()\n",
    "# optimizer = optim.Adam(linear_prob.parameters(), lr=1e-4)\n",
    "all_reprs_labels_metadata_train = []\n",
    "all_reprs = []\n",
    "all_labels = []\n",
    "for i, batch in enumerate(tqdm(loader, desc=desc)):\n",
    "    batch = deepcopy(batch)\n",
    "    images_augs, images, labels, meta_data = batch\n",
    "    images_augs = images_augs.cuda()\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    \n",
    "    reprs = model(images).detach()\n",
    "    all_reprs.append(reprs.cpu().numpy())\n",
    "    all_labels.append(labels.cpu().numpy())\n",
    "    all_reprs_labels_metadata_train.append((reprs, labels, meta_data))\n",
    "\n",
    "    # logits = linear_prob(reprs)\n",
    "    # loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "    \n",
    "    # optimizer.zero_grad()\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "all_reprs = np.concatenate(all_reprs, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train linear model on reprs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKlearn logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/abbasgln/.conda/envs/mttt/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "LR.fit(all_reprs, all_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "# linear_prob: LinearProb = LinearProb(512, 2, metric_calculator=metric_calculator, log_wandb=False)\n",
    "# linear_prob.train(all_reprs_labels_metadata_train,\n",
    "#                   epochs=15,\n",
    "#                   lr=5e-3\n",
    "#                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get test reprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7137a39f4e6452cbf539c891a9f0ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/1990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = test_loader\n",
    "\n",
    "desc = \"test\"\n",
    "\n",
    "all_reprs_labels_metadata_test = []\n",
    "all_reprs_test = []\n",
    "all_labels_test = []\n",
    "for i, batch in enumerate(tqdm(loader, desc=desc)):\n",
    "    batch = deepcopy(batch)\n",
    "    images_augs, images, labels, meta_data = batch\n",
    "    images_augs = images_augs.cuda()\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    \n",
    "    reprs = model(images).detach()\n",
    "    all_reprs_test .append(reprs.cpu().numpy())\n",
    "    all_labels_test.append(labels.cpu().numpy())\n",
    "    all_reprs_labels_metadata_test.append((reprs, labels, meta_data))\n",
    "                    \n",
    "    # # Update metrics   \n",
    "    # metric_calculator.update(\n",
    "    #     batch_meta_data = meta_data,\n",
    "    #     probs = nn.functional.softmax(logits, dim=-1).detach().cpu(),\n",
    "    #     labels = labels.detach().cpu(),\n",
    "    # )\n",
    "all_reprs_test = np.concatenate(all_reprs_test, axis=0)\n",
    "all_labels_test = np.concatenate(all_labels_test, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maybe train on test before prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Balance the test set for training\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# indices_class_0 = np.where(all_labels_test == 0)[0]\n",
    "# indices_class_1 = np.where(all_labels_test == 1)[0]\n",
    "\n",
    "# # Randomly sample indices from class 0 to match the number of class 1 indices\n",
    "# indices_class_0_sampled, _ = train_test_split(indices_class_0, train_size=len(indices_class_1), random_state=0)\n",
    "# balanced_idx_test = np.concatenate([indices_class_0_sampled[:int(1.0*len(indices_class_1))], indices_class_1[:int(1.0*len(indices_class_1))]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train using test set and train set\n",
    "# LR = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "# # LR.fit(\n",
    "# #     np.concatenate([all_reprs_test[balanced_idx_test, :], all_reprs], axis=0),\n",
    "# #     np.concatenate([all_labels_test[balanced_idx_test], all_labels], axis=0)\n",
    "# # )\n",
    "# LR.fit(all_reprs_test[balanced_idx_test, :], all_labels_test[balanced_idx_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train using pseudo labels of test set\n",
    "# LR_preds = LR.predict_proba(all_reprs_test[balanced_idx_test,:]).argmax(axis=1)\n",
    "# LR = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "# LR.fit(\n",
    "#     np.concatenate([all_reprs_test[balanced_idx_test, :], all_reprs], axis=0),\n",
    "#     np.concatenate([LR_preds, all_labels], axis=0)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logisitic regression predictions\n",
    "LR_probs = LR.predict_proba(all_reprs_test)\n",
    "\n",
    "# Update metrics\n",
    "metric_calculator.reset()\n",
    "probs = torch.tensor(LR_probs)\n",
    "labels = torch.tensor(all_labels_test)\n",
    "invs = torch.cat([meta_data[\"pct_cancer\"] for _, _, meta_data in all_reprs_labels_metadata_test])\n",
    "ids = torch.cat([meta_data[\"id\"] for _, _, meta_data in all_reprs_labels_metadata_test])\n",
    "for i, id_tensor in enumerate(ids):\n",
    "    id = id_tensor.item()\n",
    "    \n",
    "    # Dict of invs\n",
    "    metric_calculator.core_id_invs[id] = invs[i]\n",
    "    \n",
    "    # Dict of probs and labels\n",
    "    if id in metric_calculator.core_id_probs:\n",
    "        metric_calculator.core_id_probs[id].append(probs[i])\n",
    "        metric_calculator.core_id_labels[id].append(labels[i])\n",
    "    else:\n",
    "        metric_calculator.core_id_probs[id] = [probs[i]]\n",
    "        metric_calculator.core_id_labels[id] = [labels[i]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear prob prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_calculator.reset()\n",
    "# linear_prob.validate(all_reprs_labels_metadata_test, desc=desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test/patch_auroc': tensor(0.6676),\n",
       " 'test/patch_accuracy': tensor(0.4920),\n",
       " 'test/all_inv_patch_auroc': tensor(0.6298),\n",
       " 'test/all_inv_patch_accuracy': tensor(0.4986),\n",
       " 'test/core_auroc': tensor(0.7270),\n",
       " 'test/core_accuracy': tensor(0.4792),\n",
       " 'test/all_inv_core_auroc': tensor(0.6719),\n",
       " 'test/all_inv_core_accuracy': tensor(0.4884)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log metrics every epoch\n",
    "metrics = metric_calculator.get_metrics()\n",
    "\n",
    "# Update best score\n",
    "(\n",
    "    best_score_updated,\n",
    "    best_score\n",
    "    ) = metric_calculator.update_best_score(metrics, desc)\n",
    "\n",
    "best_score_updated = copy(best_score_updated)\n",
    "best_score = copy(best_score)\n",
    "        \n",
    "# Log metrics\n",
    "metrics_dict = {\n",
    "    f\"{desc}/{key}\": value for key, value in metrics.items()\n",
    "    }\n",
    "metrics_dict.update(best_score) if desc == \"val\" else None \n",
    "\n",
    "\n",
    "# wandb.log(\n",
    "#     metrics_dict,\n",
    "#     )\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log with wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "group=f\"offline_vicreg_finetune_gn_loco\"\n",
    "name= group + f\"_{LEAVE_OUT}\"\n",
    "wandb.init(project=\"tta\", entity=\"mahdigilany\", name=name, group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e410c1f7d294a84a0a90d80abca2d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.017 MB of 0.017 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>test/all_inv_core_accuracy</td><td>▁</td></tr><tr><td>test/all_inv_core_auroc</td><td>▁</td></tr><tr><td>test/all_inv_patch_accuracy</td><td>▁</td></tr><tr><td>test/all_inv_patch_auroc</td><td>▁</td></tr><tr><td>test/core_accuracy</td><td>▁</td></tr><tr><td>test/core_auroc</td><td>▁</td></tr><tr><td>test/patch_accuracy</td><td>▁</td></tr><tr><td>test/patch_auroc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>test/all_inv_core_accuracy</td><td>0.7422</td></tr><tr><td>test/all_inv_core_auroc</td><td>0.72766</td></tr><tr><td>test/all_inv_patch_accuracy</td><td>0.66819</td></tr><tr><td>test/all_inv_patch_auroc</td><td>0.65275</td></tr><tr><td>test/core_accuracy</td><td>0.76589</td></tr><tr><td>test/core_auroc</td><td>0.8132</td></tr><tr><td>test/patch_accuracy</td><td>0.68636</td></tr><tr><td>test/patch_auroc</td><td>0.72705</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">offline_memo_2aug_gn_loco_CRCEO</strong> at: <a href='https://wandb.ai/mahdigilany/tta/runs/cysluyl7' target=\"_blank\">https://wandb.ai/mahdigilany/tta/runs/cysluyl7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240111_120559-cysluyl7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# os.environ[\"WANDB_MODE\"] = \"enabled\"\n",
    "metrics_dict.update({\"epoch\": 0})\n",
    "wandb.log(\n",
    "    metrics_dict,\n",
    "    )\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New file descriptor limits - Soft: 4096, Hard: 4096\n"
     ]
    }
   ],
   "source": [
    "import resource\n",
    "\n",
    "def increase_file_descriptor_limit(new_limit):\n",
    "    # Get the current soft and hard limits\n",
    "    soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "\n",
    "    # Set the new soft limit (cannot exceed the hard limit)\n",
    "    new_soft_limit = min(new_limit, hard)\n",
    "    resource.setrlimit(resource.RLIMIT_NOFILE, (new_soft_limit, hard))\n",
    "\n",
    "    # Verify and return the new limits\n",
    "    new_soft, new_hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "    return new_soft, new_hard\n",
    "\n",
    "# Increase the limit\n",
    "new_limit = 4096*2\n",
    "new_soft, new_hard = increase_file_descriptor_limit(new_limit)\n",
    "print(f\"New file descriptor limits - Soft: {new_soft}, Hard: {new_hard}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
