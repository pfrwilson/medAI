{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fs01/home/abbasgln/codes/medAI/projects/tta\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Loading environment variables\n",
    "load_dotenv()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import typing as tp\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataclasses import dataclass, field\n",
    "import logging\n",
    "import wandb\n",
    "\n",
    "import medAI\n",
    "from medAI.utils.setup import BasicExperiment, BasicExperimentConfig\n",
    "\n",
    "from utils.metrics import MetricCalculator\n",
    "\n",
    "from timm.optim.optim_factory import create_optimizer\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "from datasets.datasets import ExactNCT2013RFImagePatches, ExactNCT2013RFPatchesWithSupportPatches, SupportPatchConfig\n",
    "from medAI.datasets.nct2013 import (\n",
    "    KFoldCohortSelectionOptions,\n",
    "    LeaveOneCenterOutCohortSelectionOptions, \n",
    "    PatchOptions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAVE_OUT='CRCEO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data MEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing positions test: 100%|██████████| 1469/1469 [02:04<00:00, 11.84it/s]\n"
     ]
    }
   ],
   "source": [
    "num_support_patches = 2\n",
    "\n",
    "\n",
    "from ttt_experiment import TTTExperimentConfig\n",
    "config = TTTExperimentConfig(\n",
    "    cohort_selection_config=LeaveOneCenterOutCohortSelectionOptions(leave_out=f\"{LEAVE_OUT}\"),\n",
    "    num_support_patches=num_support_patches,\n",
    "    include_query_patch=False,\n",
    "    )\n",
    "\n",
    "from baseline_experiment import BaselineConfig\n",
    "from torchvision.transforms import v2 as T\n",
    "from torchvision.tv_tensors import Image as TVImage\n",
    "\n",
    "class Transform:\n",
    "    def __init__(selfT, augment=False):\n",
    "        selfT.augment = augment\n",
    "        selfT.size = (256, 256)\n",
    "    \n",
    "    def __call__(selfT, item):\n",
    "        patch = item.pop(\"patch\")\n",
    "        patch = copy(patch)\n",
    "        patch = (patch - patch.min()) / (patch.max() - patch.min()) \\\n",
    "            if config.instance_norm else patch\n",
    "        patch = TVImage(patch)\n",
    "        patch = T.Resize(selfT.size, antialias=True)(patch).float()\n",
    "\n",
    "        # Support patches\n",
    "        support_patches = item.pop(\"support_patches\")\n",
    "        support_patches = copy(support_patches)\n",
    "        # Normalize support patches along last two dimensions\n",
    "        support_patches = (support_patches - support_patches.min(axis=(1, 2), keepdims=True)) \\\n",
    "        / (support_patches.max(axis=(1,2), keepdims=True) \\\n",
    "            - support_patches.min(axis=(1, 2), keepdims=True)) if config.instance_norm else support_patches\n",
    "        support_patches = TVImage(support_patches)\n",
    "        support_patches = T.Resize(selfT.size, antialias=True)(support_patches).float()\n",
    "        \n",
    "        # Augment support patches\n",
    "        transform = T.Compose([\n",
    "            T.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n",
    "            T.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0.5),\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomVerticalFlip(p=0.5),\n",
    "        ])   \n",
    "        support_patches_aug1, support_patches_aug2 = transform(support_patches, support_patches)\n",
    "        \n",
    "        if selfT.augment:\n",
    "            patch = transform(patch)\n",
    "        \n",
    "        label = torch.tensor(item[\"grade\"] != \"Benign\").long()\n",
    "        return support_patches_aug1, support_patches_aug2, patch, label, item\n",
    "\n",
    "\n",
    "# val_ds = ExactNCT2013RFPatchesWithSupportPatches(\n",
    "#     split=\"val\",\n",
    "#     transform=Transform(),\n",
    "#     cohort_selection_options=config.cohort_selection_config,\n",
    "#     patch_options=config.patch_config,\n",
    "#     support_patch_config=SupportPatchConfig(\n",
    "#         num_support_patches=config.num_support_patches,\n",
    "#         include_query_patch=config.include_query_patch\n",
    "#     ),\n",
    "#     debug=config.debug,\n",
    "# )\n",
    "        \n",
    "test_ds = ExactNCT2013RFPatchesWithSupportPatches(\n",
    "    split=\"test\",\n",
    "    transform=Transform(),\n",
    "    cohort_selection_options=config.cohort_selection_config,\n",
    "    patch_options=config.patch_config,\n",
    "    support_patch_config=SupportPatchConfig(\n",
    "        num_support_patches=config.num_support_patches,\n",
    "        include_query_patch=config.include_query_patch\n",
    "    ),\n",
    "    debug=config.debug,\n",
    ")\n",
    "\n",
    "\n",
    "# val_loader = DataLoader(\n",
    "#     val_ds, batch_size=config.batch_size_test, shuffle=config.shffl_test, num_workers=4\n",
    "# )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=config.batch_size_test, shuffle=config.shffl_test, num_workers=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ttt_model import TTTModel, TTTConfig\n",
    "adaptation_steps=1\n",
    "adaptation_lr=0.001\n",
    "beta_byol=1.0\n",
    "\n",
    "model_config = TTTConfig(adaptation_steps=adaptation_steps, adaptation_lr=adaptation_lr, beta_byol=beta_byol)\n",
    "\n",
    "# Create the model\n",
    "model: nn.Module = TTTModel(model_config)\n",
    "\n",
    "CHECKPOINT_PATH = os.path.join(os.getcwd(), f'logs/tta/ttt_2+0sprt_JT_0.1beta_loco/ttt_2+0sprt_JT_0.1beta_loco_{LEAVE_OUT}/', 'best_model.ckpt')\n",
    "\n",
    "model.load_state_dict(torch.load(CHECKPOINT_PATH)['model'])\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "a = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run test MEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fab665117b443c3a72a0ba481219d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/1715 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = test_loader\n",
    "\n",
    "\n",
    "metric_calculator = MetricCalculator()\n",
    "desc = \"test\"\n",
    "\n",
    "model.eval()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for i, batch in enumerate(tqdm(loader, desc=desc)):\n",
    "    images_aug_1, images_aug_2, images, labels, meta_data = batch\n",
    "    images_aug_1 = images_aug_1.cuda()\n",
    "    images_aug_2 = images_aug_2.cuda()\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    \n",
    "    (logits, \n",
    "    total_loss_avg,\n",
    "    ce_loss_avg,\n",
    "    byol_loss_avg\n",
    "    ) = model(images_aug_1, images_aug_2, images, labels, training=False)\n",
    "        \n",
    "    # Update metrics   \n",
    "    metric_calculator.update(\n",
    "        batch_meta_data = meta_data,\n",
    "        probs = nn.functional.softmax(logits, dim=-1).detach().cpu(),\n",
    "        labels = labels.detach().cpu(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test/patch_auroc': tensor(0.7108),\n",
       " 'test/patch_accuracy': tensor(0.6311),\n",
       " 'test/all_inv_patch_auroc': tensor(0.6423),\n",
       " 'test/all_inv_patch_accuracy': tensor(0.6206),\n",
       " 'test/core_auroc': tensor(0.8053),\n",
       " 'test/core_accuracy': tensor(0.7023),\n",
       " 'test/all_inv_core_auroc': tensor(0.7208),\n",
       " 'test/all_inv_core_accuracy': tensor(0.6888)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log metrics every epoch\n",
    "metrics = metric_calculator.get_metrics()\n",
    "\n",
    "# Update best score\n",
    "(\n",
    "    best_score_updated,\n",
    "    best_score\n",
    "    ) = metric_calculator.update_best_score(metrics, desc)\n",
    "\n",
    "best_score_updated = copy(best_score_updated)\n",
    "best_score = copy(best_score)\n",
    "        \n",
    "# Log metrics\n",
    "metrics_dict = {\n",
    "    f\"{desc}/{key}\": value for key, value in metrics.items()\n",
    "    }\n",
    "metrics_dict.update(best_score) if desc == \"val\" else None \n",
    "\n",
    "\n",
    "# wandb.log(\n",
    "#     metrics_dict,\n",
    "#     )\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdigilany\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/fs01/home/abbasgln/codes/medAI/projects/tta/wandb/run-20231230_193800-p76rom5g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mahdigilany/tta/runs/p76rom5g' target=\"_blank\">offline_ttt_2+0sprt_0.1beta_e-3adptlr_loco_CRCEO</a></strong> to <a href='https://wandb.ai/mahdigilany/tta' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mahdigilany/tta' target=\"_blank\">https://wandb.ai/mahdigilany/tta</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mahdigilany/tta/runs/p76rom5g' target=\"_blank\">https://wandb.ai/mahdigilany/tta/runs/p76rom5g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mahdigilany/tta/runs/p76rom5g?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f30f1d4f430>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "group=f\"offline_ttt_{num_support_patches}+0sprt_0.1beta_e-3adptlr_loco\"\n",
    "name= group + f\"_{LEAVE_OUT}\"\n",
    "wandb.init(project=\"tta\", entity=\"mahdigilany\", name=name, group=group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75cbca2ee940437eabb26943c2dd8650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.016 MB of 0.016 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>test/all_inv_core_accuracy</td><td>▁</td></tr><tr><td>test/all_inv_core_auroc</td><td>▁</td></tr><tr><td>test/all_inv_patch_accuracy</td><td>▁</td></tr><tr><td>test/all_inv_patch_auroc</td><td>▁</td></tr><tr><td>test/core_accuracy</td><td>▁</td></tr><tr><td>test/core_auroc</td><td>▁</td></tr><tr><td>test/patch_accuracy</td><td>▁</td></tr><tr><td>test/patch_auroc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>test/all_inv_core_accuracy</td><td>0.68884</td></tr><tr><td>test/all_inv_core_auroc</td><td>0.7208</td></tr><tr><td>test/all_inv_patch_accuracy</td><td>0.62065</td></tr><tr><td>test/all_inv_patch_auroc</td><td>0.64228</td></tr><tr><td>test/core_accuracy</td><td>0.70232</td></tr><tr><td>test/core_auroc</td><td>0.80528</td></tr><tr><td>test/patch_accuracy</td><td>0.63108</td></tr><tr><td>test/patch_auroc</td><td>0.71077</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">offline_ttt_2+0sprt_0.1beta_e-3adptlr_loco_CRCEO</strong> at: <a href='https://wandb.ai/mahdigilany/tta/runs/p76rom5g' target=\"_blank\">https://wandb.ai/mahdigilany/tta/runs/p76rom5g</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231230_193800-p76rom5g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_dict.update({\"epoch\": 0})\n",
    "wandb.log(\n",
    "    metrics_dict,\n",
    "    )\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
